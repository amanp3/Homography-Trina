{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d719188c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Aman Penmetcha\n",
    "#Written for AVATRINA,  Feb 2022\n",
    "#Code to generate 360 Birds eye of TRINA surrounding using 4 usb cameras\n",
    "\n",
    "from re import sub\n",
    "from turtle import back, right\n",
    "import numpy as np\n",
    "import cv2\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import io\n",
    "import imutils\n",
    "cv2.ocl.setUseOpenCL(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb4cefcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#where is each camera\n",
    "frontIndex = 3\n",
    "leftIndex = 0\n",
    "backIndex = 1\n",
    "rightIndex = 2\n",
    "spareCam = 1\n",
    "\n",
    "##########\n",
    "#this function takes the file name as a string eg: rightCamDesired.png and which camera: 1, 3, 5, or 7 and\n",
    "#stores a image to later calculate homography with\n",
    "\n",
    "def takePicture(fileName, camNumber):\n",
    "    cap = cv2.VideoCapture(camNumber) #choose which camera\n",
    "    while(True):\n",
    "        ret, frame = cap.read() # return a single frame in variable `frame`\n",
    "        cv2.imshow('Take Picture for: ' + fileName + '||| y for take picture q for dont take picture', frame) #display the captured image\n",
    "        if cv2.waitKey(1) & 0xFF == ord('y'): #save on pressing 'y' \n",
    "            cv2.imwrite(fileName, frame)\n",
    "            cv2.destroyAllWindows()\n",
    "            break\n",
    "        elif cv2.waitKey(1) == ord('q'): #dont save the picture on pressing 'q'\n",
    "            print('No picture taken')\n",
    "            cv2.destroyAllWindows()\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "\n",
    "\n",
    "def calibrate():\n",
    "    #taking pics for the gram \n",
    "    \n",
    "    # takePicture('frontCamActual.png', frontIndex)\n",
    "    # takePicture('frontCamDesired.png', spareCam) \n",
    "    # takePicture('rightCamActual.png', rightIndex)  \n",
    "    # takePicture('rightCamDesired.png',  spareCam) \n",
    "    # takePicture('leftCamActual.png', leftIndex)\n",
    "    # takePicture('leftCamDesired.png', spareCam)\n",
    "    # takePicture('backCamActual.png', backIndex)\n",
    "    # takePicture('backCamDesired.png', spareCam)\n",
    "    \n",
    "\n",
    "    takePicture('frontStitchingImage.png', frontIndex)\n",
    "    takePicture('leftStitchingImage.png', leftIndex)\n",
    "    takePicture('backStitchingImage.png', backIndex)\n",
    "    takePicture('rightStitchingImage.png', rightIndex)\n",
    "\n",
    "#functions for stitching below\n",
    "def detectAndDescribe(image, method=None):\n",
    "    \"\"\"\n",
    "    Compute key points and feature descriptors using an specific method\n",
    "    \"\"\"\n",
    "    \n",
    "    assert method is not None, \"You need to define a feature detection method. Values are: 'sift', 'surf'\"\n",
    "    \n",
    "    # detect and extract features from the image\n",
    "    if method == 'sift':\n",
    "        descriptor = cv2.xfeatures2d.SIFT_create()\n",
    "    elif method == 'surf':\n",
    "        descriptor = cv2.xfeatures2d.SURF_create()\n",
    "    elif method == 'brisk':\n",
    "        descriptor = cv2.BRISK_create()\n",
    "    elif method == 'orb':\n",
    "        descriptor = cv2.ORB_create(nfeatures = 50000)\n",
    "        \n",
    "    # get keypoints and descriptors\n",
    "    (kps, features) = descriptor.detectAndCompute(image, None)\n",
    "    \n",
    "    return (kps, features)\n",
    "\n",
    "def createMatcher(method,crossCheck):\n",
    "    \"Create and return a Matcher Object\"\n",
    "    \n",
    "    if method == 'sift' or method == 'surf':\n",
    "        bf = cv2.BFMatcher(cv2.NORM_L2, crossCheck=crossCheck)\n",
    "    elif method == 'orb' or method == 'brisk':\n",
    "        bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=crossCheck)\n",
    "    return bf\n",
    "\n",
    "def matchKeyPointsBF(featuresA, featuresB, method):\n",
    "    bf = createMatcher(method, crossCheck=True)\n",
    "        \n",
    "    # Match descriptors.\n",
    "    best_matches = bf.match(featuresA,featuresB)\n",
    "    \n",
    "    # Sort the features in order of distance.\n",
    "    # The points with small distance (more similarity) are ordered first in the vector\n",
    "    rawMatches = sorted(best_matches, key = lambda x:x.distance)\n",
    "    print(\"Raw matches (Brute force):\", len(rawMatches))\n",
    "    return rawMatches\n",
    "\n",
    "def matchKeyPointsKNN(featuresA, featuresB, ratio, method):\n",
    "    bf = createMatcher(method, crossCheck=False)\n",
    "    # compute the raw matches and initialize the list of actual matches\n",
    "    rawMatches = bf.knnMatch(featuresA, featuresB, 2)\n",
    "    print(\"Raw matches (knn):\", len(rawMatches))\n",
    "    matches = []\n",
    "\n",
    "    # loop over the raw matches\n",
    "    for m,n in rawMatches:\n",
    "        # ensure the distance is within a certain ratio of each\n",
    "        # other (i.e. Lowe's ratio test)\n",
    "        if m.distance < n.distance * ratio:\n",
    "            matches.append(m)\n",
    "    return matches\n",
    "\n",
    "def getHomography(kpsA, kpsB, featuresA, featuresB, matches, reprojThresh):\n",
    "    # convert the keypoints to numpy arrays\n",
    "    kpsA = np.float32([kp.pt for kp in kpsA])\n",
    "    kpsB = np.float32([kp.pt for kp in kpsB])\n",
    "    \n",
    "    if len(matches) > 4:\n",
    "\n",
    "        # construct the two sets of points\n",
    "        ptsA = np.float32([kpsA[m.queryIdx] for m in matches])\n",
    "        ptsB = np.float32([kpsB[m.trainIdx] for m in matches])\n",
    "        \n",
    "        # estimate the homography between the sets of points\n",
    "        (H, status) = cv2.findHomography(ptsA, ptsB, cv2.RANSAC,\n",
    "            reprojThresh)\n",
    "\n",
    "        return (matches, H, status)\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def get_img_from_fig(fig, dpi=180):\n",
    "    buf = io.BytesIO()\n",
    "    fig.savefig(buf, format=\"png\", dpi=dpi)\n",
    "    buf.seek(0)\n",
    "    img_arr = np.frombuffer(buf.getvalue(), dtype=np.uint8)\n",
    "    buf.close()\n",
    "    img = cv2.imdecode(img_arr, 1)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    return img\n",
    "\n",
    "#comment out calibrate line below if you want to skip calibration \n",
    "#if not commented you can still skip taking pictures but you will have to press q 8 times\n",
    "# calibrate()\n",
    "\n",
    "#images paths to calculate top down homography from\n",
    "pathFrontCamActual = r'C:\\Users\\Aman\\Desktop\\School\\Python\\TRINA\\frontCamActual.png'\n",
    "pathFrontCamDesired = r'C:\\Users\\Aman\\Desktop\\School\\Python\\TRINA\\frontCamDesired.png'\n",
    "pathRightCamActual = r'C:\\Users\\Aman\\Desktop\\School\\Python\\TRINA\\rightCamActual.png'\n",
    "pathRightCamDesired = r'C:\\Users\\Aman\\Desktop\\School\\Python\\TRINA\\rightCamDesired.png'\n",
    "pathLeftCamActual = r'C:\\Users\\Aman\\Desktop\\School\\Python\\TRINA\\leftCamActual.png'\n",
    "pathLeftCamDesired = r'C:\\Users\\Aman\\Desktop\\School\\Python\\TRINA\\leftCamDesired.png'\n",
    "pathBackCamActual = r'C:\\Users\\Aman\\Desktop\\School\\Python\\TRINA\\backCamActual.png'\n",
    "pathBackCamDesired = r'C:\\Users\\Aman\\Desktop\\School\\Python\\TRINA\\backCamDesired.png'\n",
    "\n",
    "\n",
    "frontActual = cv2.imread(pathFrontCamActual)\n",
    "frontDesired = cv2.imread(pathFrontCamDesired)\n",
    "rightActual = cv2.imread(pathRightCamActual)\n",
    "rightDesired = cv2.imread(pathRightCamDesired)\n",
    "leftActual = cv2.imread(pathLeftCamActual)\n",
    "leftDesired = cv2.imread(pathLeftCamDesired)\n",
    "backActual = cv2.imread(pathBackCamActual)\n",
    "backDesired = cv2.imread(pathBackCamDesired)\n",
    "\n",
    "t = time.time()\n",
    "\n",
    "#patternSize stores the size of the chessboard you are looking for\n",
    "patternSize = (8,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07c5b441",
   "metadata": {},
   "outputs": [],
   "source": [
    "retFA, cornersFrontActual = cv2.findChessboardCorners(frontActual, patternSize)\n",
    "retFD, cornersFrontDesired = cv2.findChessboardCorners(frontDesired, patternSize)\n",
    "retRA, cornersRightActual = cv2.findChessboardCorners(rightActual, patternSize)\n",
    "retRD, cornersRightDesired = cv2.findChessboardCorners(rightDesired, patternSize)\n",
    "retLA, cornersLeftActual = cv2.findChessboardCorners(leftActual, patternSize)\n",
    "retLD, cornersLeftDesired = cv2.findChessboardCorners(leftDesired, patternSize)\n",
    "retBA, cornersBackActual = cv2.findChessboardCorners(backActual, patternSize)\n",
    "retBD, cornersBackDesired = cv2.findChessboardCorners(backDesired, patternSize)\n",
    "\n",
    "Hfront, _1 = cv2.findHomography(cornersFrontActual, cornersFrontDesired)\n",
    "Hright, _2 = cv2.findHomography(cornersRightActual, cornersRightDesired)\n",
    "Hleft, _3 = cv2.findHomography(cornersLeftActual, cornersLeftDesired)\n",
    "Hback, _4 = cv2.findHomography(cornersBackActual, cornersBackDesired)\n",
    "print(\"Top Down Matricies Computed\")\n",
    "# imgTemp1 = cv2.warpPerspective(cv2.imread(r'C:\\Users\\Aman\\Desktop\\School\\Python\\frontStitchingImage.png'), Hfront, (frontActual.shape[1], frontActual.shape[0]))\n",
    "# cv2.imwrite('frontStitchingImageWarped.png', imgTemp1)\n",
    "# imgTemp2 = cv2.warpPerspective(cv2.imread(r'C:\\Users\\Aman\\Desktop\\School\\Python\\leftStitchingImage.png'), Hleft, (frontActual.shape[1], frontActual.shape[0]))\n",
    "# cv2.imwrite('leftStitchingImageWarped.png', imgTemp2)\n",
    "# print(\"Done\")\n",
    "# cv2.imshow('Front Cam Warped', frontCam_warp)\n",
    "# cv2.imshow('Right Cam Warped', rightCam_warp)\n",
    "# cv2.imshow('Left Cam Warped', leftCam_warp)\n",
    "\n",
    "#stitching starts here\n",
    "feature_extractor = 'orb' # one of 'sift', 'surf', 'brisk', 'orb'\n",
    "feature_matching = 'bf'\n",
    "\n",
    "#images to calculate stitching matricies from\n",
    "frontStitchImage = cv2.imread(r'C:\\Users\\Aman\\Desktop\\School\\Python\\TRINA\\frontStitchingImage.png')\n",
    "leftStitchImage = cv2.imread(r'C:\\Users\\Aman\\Desktop\\School\\Python\\TRINA\\leftStitchingImage.png')\n",
    "backStitchImage = cv2.imread(r'C:\\Users\\Aman\\Desktop\\School\\Python\\TRINA\\backStitchingImage.png')\n",
    "rightStitchImage = cv2.imread(r'C:\\Users\\Aman\\Desktop\\School\\Python\\TRINA\\rightStitchingImage.png')\n",
    "\n",
    "#test images\n",
    "# frontStitchImage = cv2.imread(r'C:\\Users\\Aman\\Desktop\\TRINA\\OPENCV\\front360Test.png')\n",
    "# leftStitchImage = cv2.imread(r'C:\\Users\\Aman\\Desktop\\TRINA\\OPENCV\\left360Test.png')\n",
    "# backStitchImage = cv2.imread(r'C:\\Users\\Aman\\Desktop\\TRINA\\OPENCV\\back360Test.png')\n",
    "# rightStitchImage = cv2.imread(r'C:\\Users\\Aman\\Desktop\\TRINA\\OPENCV\\right360Test.png')\n",
    "\n",
    "# frontCam_warp_gray = cv2.cvtColor(frontCam_warp, cv2.COLOR_RGB2GRAY)\n",
    "# leftCam_warp_gray = cv2.cvtColor(leftCam_warp, cv2.COLOR_RGB2GRAY)\n",
    "# backCam_warp_gray = cv2.cvtColor(backCam_warp, cv2.COLOR_RGB2GRAY)\n",
    "# rightCam_warp_gray = cv2.cvtColor(rightCam_warp, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "#pass in the grayscale of images that need to be stitched (these will be the top down warped images)\n",
    "#needs both grayscale and normal to compute the stitching matrix properly\n",
    "def calculateStitchingMatrix(img1, img1Gray, img2, img2Gray):\n",
    "    kpsA, featuresA = detectAndDescribe(img1Gray, method=feature_extractor)\n",
    "    kpsB, featuresB = detectAndDescribe(img2Gray, method=feature_extractor)\n",
    "    \n",
    "\n",
    "    # display the keypoints and features detected on both images\n",
    "    # fig, (ax1,ax2) = plt.subplots(nrows=1, ncols=2, figsize=(20,8), constrained_layout=False)\n",
    "    # ax1.imshow(cv2.drawKeypoints(img1,kpsA,None,color=(0,255,0)))\n",
    "    # ax1.set_xlabel(\"(a)\", fontsize=14)\n",
    "    # ax2.imshow(cv2.drawKeypoints(img2,kpsB,None,color=(0,255,0)))\n",
    "    # ax2.set_xlabel(\"(b)\", fontsize=14)\n",
    "    # plt.show()\n",
    "\n",
    "    if feature_matching == 'bf':\n",
    "        matches = matchKeyPointsBF(featuresA, featuresB, method=feature_extractor)\n",
    "        img3 = cv2.drawMatches(img1,kpsA,img2,kpsB,matches[:100],\n",
    "                            None,flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)\n",
    "    elif feature_matching == 'knn':\n",
    "        matches = matchKeyPointsKNN(featuresA, featuresB, ratio=0.75, method=feature_extractor)\n",
    "        img3 = cv2.drawMatches(img1,kpsA,img2,kpsB,np.random.choice(matches,100),\n",
    "                            None,flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)\n",
    "\n",
    "    plt.imshow(img3)\n",
    "    plt.show()\n",
    "\n",
    "    M = getHomography(kpsA, kpsB, featuresA, featuresB, matches, reprojThresh=4)\n",
    "    if M is None:\n",
    "        print(\"Error! Stitching Homography Matrix couldnt be calculated for kpsA and kpsB\")\n",
    "    (matches, Hstitch, status) = M\n",
    "    return Hstitch\n",
    "\n",
    "def warpTwoImages(img1, img2, H):\n",
    "    '''warp img2 to img1 with homograph H'''\n",
    "    h1,w1 = img1.shape[:2]\n",
    "    h2,w2 = img2.shape[:2]\n",
    "    pts1 = np.float32([[0,0],[0,h1],[w1,h1],[w1,0]]).reshape(-1,1,2)\n",
    "    pts2 = np.float32([[0,0],[0,h2],[w2,h2],[w2,0]]).reshape(-1,1,2)\n",
    "    pts2_ = cv2.perspectiveTransform(pts2, H)\n",
    "    pts = np.concatenate((pts1, pts2_), axis=0)\n",
    "    [xmin, ymin] = np.int32(pts.min(axis=0).ravel() - 0.5)\n",
    "    [xmax, ymax] = np.int32(pts.max(axis=0).ravel() + 0.5)\n",
    "    t = [-xmin,-ymin]\n",
    "    Ht = np.array([[1,0,t[0]],[0,1,t[1]],[0,0,1]]) # translate\n",
    "\n",
    "    result = cv2.warpPerspective(img2, Ht.dot(H), (xmax-xmin, ymax-ymin))\n",
    "    result[t[1]:h1+t[1],t[0]:w1+t[0]] = img1\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33689617",
   "metadata": {},
   "outputs": [],
   "source": [
    "#applies top down homography Uncomment next block of 4 lines if you want this to run\n",
    "frontStitchImage_warp = cv2.warpPerspective(frontStitchImage, Hfront, (frontStitchImage.shape[1], frontStitchImage.shape[0]))\n",
    "leftStitchImage_warp = cv2.warpPerspective(leftStitchImage, Hleft, (leftStitchImage.shape[1], leftStitchImage.shape[0]))\n",
    "backStitchImage_warp = cv2.warpPerspective(backStitchImage, Hback, (backStitchImage.shape[1], backStitchImage.shape[0]))\n",
    "rightStitchImage_warp = cv2.warpPerspective(rightStitchImage, Hright, (rightStitchImage.shape[1], rightStitchImage.shape[0]))\n",
    "\n",
    "#skips top down homography for debugging\n",
    "# frontStitchImage_warp = frontStitchImage\n",
    "# leftStitchImage_warp = leftStitchImage\n",
    "# backStitchImage_warp = backStitchImage\n",
    "# rightStitchImage_warp = rightStitchImage\n",
    "\n",
    "\n",
    "frontStitchImage_warp_gray = cv2.cvtColor(frontStitchImage_warp, cv2.COLOR_RGB2GRAY)\n",
    "leftStitchImage_warp_gray = cv2.cvtColor(leftStitchImage_warp, cv2.COLOR_RGB2GRAY)\n",
    "backStitchImage_warp_gray = cv2.cvtColor(backStitchImage_warp, cv2.COLOR_RGB2GRAY)\n",
    "rightStitchImage_warp_gray = cv2.cvtColor(rightStitchImage_warp, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "HFL = calculateStitchingMatrix(frontStitchImage_warp, frontStitchImage_warp_gray, leftStitchImage_warp, leftStitchImage_warp_gray)\n",
    "subStitchFL = warpTwoImages(leftStitchImage_warp, frontStitchImage_warp, HFL)\n",
    "\n",
    "subStitchFL_gray = cv2.cvtColor(subStitchFL, cv2.COLOR_RGB2GRAY)\n",
    "HFLB = calculateStitchingMatrix(subStitchFL, subStitchFL_gray, backStitchImage_warp, backStitchImage_warp_gray)\n",
    "\n",
    "subStitchFLB = warpTwoImages(backStitchImage_warp, subStitchFL, HFLB)\n",
    "\n",
    "subStitchFLB_gray = cv2.cvtColor(subStitchFLB, cv2.COLOR_RGB2GRAY)\n",
    "HFLBR = calculateStitchingMatrix(subStitchFLB, subStitchFLB_gray, rightStitchImage_warp, rightStitchImage_warp_gray)\n",
    "subStitchFLBR = warpTwoImages(rightStitchImage_warp, subStitchFLB, HFLBR)\n",
    "subStitchFLBR = cv2.resize(subStitchFLBR, (720, 480))\n",
    "cv2.imshow('subStitchFLBR', subStitchFLBR)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "print(\"DONE COMPUTING\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0834281e",
   "metadata": {},
   "outputs": [],
   "source": [
    "capFront = cv2.VideoCapture(frontIndex)\n",
    "capLeft = cv2.VideoCapture(leftIndex)\n",
    "capBack = cv2.VideoCapture(backIndex)\n",
    "capRight = cv2.VideoCapture(rightIndex)\n",
    "\n",
    "pTime = 0\n",
    "while True:\n",
    "    cTime = time.time()\n",
    "    fps = 1/(cTime - pTime)\n",
    "    pTime = cTime\n",
    "\n",
    "    ret, frameFront = capFront.read()\n",
    "    ret, frameLeft = capLeft.read()\n",
    "    ret, frameBack = capBack.read()\n",
    "    ret, frameRight = capRight.read()\n",
    "\n",
    "    #circumventing top down homography for testing\n",
    "    # frontCam_warp = frameFront\n",
    "    # leftCam_warp = frameLeft\n",
    "    # backCam_warp = frameBack\n",
    "    # rightCam_warp = frameRight \n",
    "\n",
    "    frontCam_warp = cv2.warpPerspective(frameFront, Hfront, (frontActual.shape[1], frontActual.shape[0]))\n",
    "    leftCam_warp = cv2.warpPerspective(frameLeft, Hleft, (leftActual.shape[1], leftActual.shape[0]))\n",
    "    backCam_warp = cv2.warpPerspective(frameBack, Hback, (backActual.shape[1], backActual.shape[0]))\n",
    "    rightCam_warp = cv2.warpPerspective(frameRight, Hright, (rightActual.shape[1], rightActual.shape[0]))\n",
    "\n",
    "    subStitchFL = warpTwoImages(leftCam_warp, frontCam_warp, HFL)\n",
    "    subStitchFL_gray = cv2.cvtColor(subStitchFL, cv2.COLOR_RGB2GRAY)\n",
    "    subStitchFLB = warpTwoImages(backCam_warp, subStitchFL, HFLB)\n",
    "    subStitchFLB_gray = cv2.cvtColor(subStitchFLB, cv2.COLOR_RGB2GRAY)\n",
    "    subStitchFLBR = warpTwoImages(rightCam_warp, subStitchFLB, HFLBR)\n",
    "\n",
    "    #display the result of top down homography and stitching\n",
    "    result = subStitchFLBR\n",
    "\n",
    "    result = cv2.resize(result, (1200, 800))\n",
    "    \n",
    "    cv2.putText(result, str(int(fps)), (10,70), cv2.FONT_HERSHEY_PLAIN, 3, (255,0,255),3)\n",
    "    cv2.imshow('front', frontCam_warp)\n",
    "    cv2.imshow('left', leftCam_warp)\n",
    "    cv2.imshow('back', backCam_warp)\n",
    "    cv2.imshow('right', rightCam_warp)\n",
    "\n",
    "    cv2.imshow('', result)\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        print(fps)\n",
    "        cv2.destroyAllWindows()\n",
    "        break\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
